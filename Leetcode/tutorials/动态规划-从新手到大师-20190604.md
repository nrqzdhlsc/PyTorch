----

原文链接：https://community.topcoder.com/tc?module=Static&d1=features&d2=040104

译者：BING

时间：20190604

----

Thursday, April 1, 2004

作者： [**vorthys**](https://community.topcoder.com/tc?module=MemberProfile&cr=299177)* TopCoder 成员*

### **简介**

如果你调查红名选手(TopCoder上排名显示颜色)，你会发现十分之九都会推荐你学习动态规划作为最佳的提升排名的手段。而这第十个同学之所以不这么干是因为他不想帮助将来的竞争对手。动态规划(简写为DP)是一种算法级数，可以用在很多计数和优化问题上。因此，如果你看到"有多少"，"最小"，"最大"，"最短"，"最长"等词汇出现在问题陈述中时，有很大几率你在看的问题是DP问题。

### **一切都从递归开始**

我会先从坏消息开始说起。为了理解DP，你必须首先坚实地掌握递归。如果递归对你来说很难理解，请多写写循环直到理解递归为止。好消息是，一旦你完全掌握了DP，问题的答案往往就是一些`for`循环。但是达到这种开悟的状态，不经过掌握递归是不可能的。.

实际上，DP中的递归关系通常很简单，因为它们允许不高效。惊人的不高效，显然不高效，都行。效率会在后面达成。

一个直白的递归的例子是，考虑最长公共子序列问题。给定两个字符串S和T，现在想找到两个字符串中的最长子序列，其中子序列的字符不需要连续出现在原始字符串中。比如，给的字符串是"ABCDE"和"DACACBE"，最长公共子序列就是"ACE"。直白的递归算法可以用伪代码写成：

```js
function LCS(S, T) is
	if S is empty or T is empty then return empty string  // 如果S空或T空就返回空字符串
	if first char of S == first char of T then // 如果S的第一个字符等于T的第一个字符，然后
		return (first char of S) + LCS(S - first char, T - first char) // 返回S的第一个字符 + LCS(S - 第一个字符， T-第一个字符)
	otherwise // 否则，第一个字符是不同的
		return longer of LCS(S - first char, T) and LCS(S, T - first char) // 返回两者中较长的
```

在第一个情形中，一个或两个字符串都为空，因此最长公共子序列为空。在第二个情形中，两个字符串的首字符相等，因此我们声明这个字符是最长公共子序列的一部分，然后递归计算剩下的字符的最长公共子序列。第三个情形中，字符串以不同的字符开始，因此至少S的第一个字符或者T的第一个字符不是最长公共子序列的字符。因此，我们递归地计算最长公共子序列，通过丢弃S的第一个字符或者T的第一个字符，并将二者的较长的作为结果。

如果你对递归感觉到很舒适，那么这个定义对你来说完全合理。但是，你的大脑的一部分一定会说：这是指数级别的复杂度。永远不会运行足够快。好吧，你是对的。这个算法非常慢。但是没事，因为我们还没结束。下一步我们将看看为什么这个算法很慢，这会给我们以启发，然后让它变得更快。

### 重叠子问题

考虑到递归版本的LCS算法中发生的事情，输入是"ABCDE"和"FGHI"。算法的过程可以总结为：

```json
LCS("ABCDE", "FGHI")
= longer of { LCS("BCDE","FGHI"),
LCS("ABCDE","GHI") }
= longer of {
longer of { LCS("CDE","FGHI"),
LCS("BCDE","GHI") },
longer of { LCS("BCDE","GHI"),
LCS("ABCDE","HI") }}
= longer of {
longer of {
longer of { LCS("DE","FGHI"), LCS("CDE","GHI") },
longer of { LCS("CDE","GHI"), LCS("BCDE","HI") }},
longer of {
longer of { LCS("CDE","GHI"), LCS("BCDE","HI") },
longer of { LCS("BCDE","HI"), LCS("ABCDE","I") }}}
= ...
```

注意特定的子问题是如何重复出现的。我们可以看到调用`LCS("CDE","GHI")`三次，以及另一个调用`LCS("BCDE","HI")`也执行了三次。最我们执行了35次`LCS("E","I")`调用。这解释了为什么算法如此慢。

小心不要从这个例子中总结错了结论。有时候人们看到这个例子会说："看，递归很慢！"但是，这个愚蠢的算法的错误之处在于毫无必要的重复，而不是愚蠢在用递归来写。

我们需要停止重复计算已经算过的步骤。这也就是DP发挥作用的地方。但是，首先我们还是先简短了解下DP的表弟，它叫**记忆化**。

### **记忆化**

记忆是一种用来记住我们在哪些输入上调用的函数的技术，并给出每个输入的答案。如果我们在同样的输入上调用函数35次，那么我们只需要简单的查表而不是重复计算。

比如，下面是使用记忆化重写的LCS算法。它取决于答案的记忆表，表用一对字符串作为索引：

```j&#39;s
function MLCS(S, T) is
if the pair <S,T> is in the memo table then
lookup and return the answer associated with the pair <S,T>
otherwise
answer = LCS(S,T)  // do the actual work for these inputs
save answer in memo table with the pair <S,T>
return answer

function LCS(S, T) is
if S is empty or T is empty then return empty string
if first char of S == first char of T then
return (first char of S) + MLCS(S - first char, T - first char)
otherwise // first chars are different
return longer of MLCS(S - first char, T) and MLCS(S, T - first char)
```

为了区分，我已经将记忆化的代码写为`MLCS`，原来的叫`LCS`。对LCS的唯一的变化是会调用MLCS，而不是反复调用自身。

In the code above, the memo table would probably be implemented as a hash table. This is a very common representation of memo tables, especially when the inputs are strings. In this particular case, however, we can do better, assuming we are willing to erase the memo table between distinct calls to the algorithm. Instead of passing around entire strings, we can pass around indices into those strings. Then the memo table can be a simple two-dimensional array indexed by integers. The catch is that we need arrays of different sizes whenever we call the main function with different initial strings. So we allocate a new array when we start the main function, and deallocate the array when we finish. We use an index of 0 to indicate that we are at the beginning of a string, and an index one past the last position in the string to indicate that we have reached the end of the string. The main function is now

在上面的代码中，记忆表可以实现为一个哈希表。这是非常常见的表示方法，尤其是输入是字符串时。在这个例子里，我们可以做得更好，

```
function MAIN-LCS(S, T) is
allocate an array A[0..length of S, 0..length of T]
initialize all entries in A to null
answer = LCS(0,0)
deallocate A
return answer
```

with LCS and MLCS as local helper functions

```
function MLCS(i, j) is
if A[i,j] == null then
A[i,j] = LCS(i,j)
return A[i,j]

function LCS(i, j) is
if i == length of S or j == length of T then return empty string
if S[i] == T[j] then
return S[i] + MLCS(i+1, j)
otherwise
return longer of MLCS(i+1, j) and MLCS(i, j+1)
```

The memoization-based algorithm processes the memo table in a top-down, demand-driven fashion. Taking the final step to full-fledged DP involves processing the memo table bottom-up, instead.

**Dynamic Programming...At Last**
If you trace through the execution of the memoization-based algorithm, you'll see that it *asks for* answers to the biggest subproblems first. But if you look at the order in which answers are actually written into the memo table, you'll see that it *fills in* answers to the smallest subproblems first. This discrepancy arises from the LIFO nature of recursion—the first invocation of a recursive function is the last to return.

DP throws away the recursion and simply focuses on filling in the table, using a few loops to initialize the table from the smallest subproblems to the biggest subproblems. In fact, as a side note for those of you interested in etymology, the word "programming" in dynamic programming refers, not to computer programming, but to the family of mathematical techniques based on filling out and manipulating tables (linear programming is perhaps the most famous member of this family).

Converting the previous algorithm to use DP is straightforward, except for one point that I'll discuss in a moment.

```
function LCS(S, T) is
allocate an array A[0..length of S, 0..length of T]
for i = length of S downto 0 do
for j = length of T downto 0 do
if i == length of S or j == length of T then
A[i,j] = empty string
else if S[i] == T[j] then
A[i,j] = S[i] + A[i+1,j]
else
A[i,j] = longer of A[i+1,j] and A[i,j+1]
answer = A[0,0]
deallocate A
return answer
```

If you compare the body of the inner loop side-by-side with the body of the previous LCS function, you can see that the two algorithms really are doing the same thing.

| DP --------------------------------------------              | Memoization --------------------------------------------     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `if i == length of S or j == length of T then  A[i,j] = empty string  else if S[i] == T[j] then  A[i,j] = S[i] + A[i+1,j]  else  A[i,j] = longer of A[i+1,j] and A[i,j+1] ` | `if i == length of S or j == length of T then return empty string if S[i] == T[j] then return S[i] + MLCS(i+1,j) otherwise return longer of MLCS(i+1,j) and MLCS(i,j+1) ` |

The main differences are that calls to MLCS have been replaced with lookups in the array, and the returns have been replaced with assignments into the array.

The most confusing part of the above DP algorithm is why the loops count backwards instead of forwards. This is actually an artifact of the way I wrote the recursive algorithm. In the recursive algorithm, it was most natural to obtain subproblems by peeling off characters from the fronts of the strings. But that means that the smaller subproblems are at the backs of the strings, which in turn means that, if you want to process the table from smallest subproblems to biggest subproblems, you end up working backward.

With DP, however, it is probably more natural to work front to back. Fortunately, this is a very easy change to make.

```
function LCS(S, T) is
allocate an array A[0..length of S, 0..length of T]
for i = 0 upto length of S do
for j = 0 upto length of T do
if i == 0 or j == 0 then
A[i,j] = empty string
else if S[i-1] == T[j-1] then
A[i,j] = A[i-1,j] + S[i-1]
else
A[i,j] = longer of A[i-1,j] and A[i,j-1]
answer = A[length of S,length of T]
deallocate A
return answer
```

This answer is fine as is, but aficionados of DP often take the further step of initializing the base cases outside the main loop, as in the following version.

```
function LCS(S, T) is
allocate an array A[0..length of S, 0..length of T]

// initialize base cases
for i = 0 upto length of S do
A[i,0] = empty string
for j = 0 upto length of T do
A[0,j] = empty string

// main loop
for i = 1 upto length of S do
for j = 1 upto length of T do
if S[i-1] == T[j-1] then
A[i,j] = A[i-1,j] + S[i-1]
else
A[i,j] = longer of A[i-1,j] and A[i,j-1]

answer = A[length of S,length of T]
deallocate A
return answer
```

**Another Example: Knapsack**
There are many variations of the knapsack problem, but here's one: Given an array C[1..K] of distinct positive integers, count how many combinations of integers in C add up to exactly N.

We begin with a straightforward recursive solution, where combos(i,m) is the number of combinations of integers in C[1..i] that add up to m.

```
function combos(i,m) is
if m = 0 then return 1
if i = 0 then return 0
if C[i] > m then return combos(i-1,m)
else return combos(i-1,m) + combos(i-1,m-C[i])
```

In the first case, there is exactly one combination of integers that adds up to 0, namely the empty combination. In the second case, we have no numbers to add so there is no way to get a non-zero sum. In the third case, C[i] is too big so the only way to add up to m is to use the integers in C[1..i]. In the last case, we count the number of combinations that do not use C[i] plus the number of combinations that do use C[i].

Notice that i is always between 0 and K, inclusive, and m is always between 0 and N, inclusive. Therefore, in the DP solution, we use an array A[0..K, 0..N]. We initialize the array from smaller values of i and m to bigger values.

```
function combos(C) is
allocate an array A[0..K, 0..N]

// initialize base cases
A[0,0] = 1
for m = 1 upto N do
A[0,m] = 0

// main loop
for i = 1 upto K do
for m = 1 upto M do
if C[i] > m then
A[i,m] = A[i-1,m]
else
A[i,m] = A[i-1,m] + A[i-1,m-C[i]]

answer = A[K,N]
deallocate A
return answer
```

This algorithm obviously takes O(K·N) time and space. With a small amount of cleverness, we can reduce the space requirement to O(N). The key is to realize that each row of the table depends only on the previous row. Therefore, we only need to keep one row in memory at a time.

With that hint, most people will go out and write the following code:

```
function combos(C) is // Warning: Buggy!
allocate an array A[0..N]

// initialize base cases
A[0] = 1
for m = 1 upto N do
A[m] = 0

// main loop
for i = 1 upto K do
for m = 1 upto N do
// if C[i] > m then A[m] is unchanged
if C[i] <= m then
A[m] = A[m] + A[m-C[i]]

answer = A[N]
deallocate A
return answer
```

Unfortunately, there's a serious bug in this code that illustrates how important it is to be careful about the order in which you fill in the table. At each iteration of the inner loop, A[1..m-1] has already been updated to hold the number of valid combinations of integers from C[1..i], whereas A[m..N] still holds the number of valid combinations of integers from C[1..i-1]. Now, look at the innermost assignment

```
A[m] = A[m] + A[m-C[i]]
```

By the time we do this assignment, we've already updated A[m-C[i]], whereas what we want here is the *previous* value of A[m-C[i]]. The fix is simply to run the inner loop backwards from N to 1 instead of forwards from 1 to N. That way, when we process A[m], we have not yet processed A[m-C[i]]. The corrected code is

```
function combos(C) is
allocate an array A[0..N]

// initialize base cases
A[0] = 1
for m = 1 upto N do
A[0,m] = 0

// main loop
for i = 1 upto K do
for m = N downto 1 do
// if C[i] > m then A[m] is unchanged
if C[i] <= m then
A[m] = A[m] + A[m-C[i]]

answer = A[N]
deallocate A
return answer
```

**Summary**
Coming up with a DP algorithm involves three main steps. Once you get good at it, you won't have to think about the steps separately, but in the beginning, it's best to go through the steps one at a time.

- **Come up with the recursive relationship.** Many beginning programmers get hung up here. If you have troubles in this step, set aside DP for awhile and go practice recursion.
- **Look for overlapping subproblems.** If there are no overlapping subproblems, then you don't need DP. If there are overlapping subproblems, see if you can characterize the subproblems with a few numbers chosen from a small range so that you can allocate an array of the right size. If you can't figure out a range of numbers that works, you can use a less structured table like a hashtable instead of an array. But if you go that route, be careful because there may end up being many more subproblems than you expected.
- **Figure out the right order to fill in the table.** Make sure that each element of the table is initialized before it is needed in the calculation of another element. Keep an open mind. Sometimes your loops will go forwards, sometimes backwards, and sometimes you'll have a mix of both. If you get stuck on this step, but you've completed the first two, then bail on DP and just go with memoization.

As with most programming skills, the best way to learn DP is to practice, practice, practice. Fortunately, the practice rooms have a wide variety of DP problems to choose from. For easy practice problems, try AvoidRoads (2003 TCO Semifinal Room 4) or ZigZag (2003 TCCC Semifinal Room 3). When you're ready for more challenging problems, try Jewelry (2003 TCO Online Round 4) or StripePainter (SRM 150 Div 1).

Good luck, and happy DP-ing!



Would you like to [write a feature?](https://community.topcoder.com/tc?module=Static&d1=features&d2=topics)